{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4e114fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\LangChain project\\learn-LangChain\\learnlangchain\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "816da9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatModel = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash-lite\",\n",
    "    google_api_key=GEMINI_API_KEY,\n",
    "    temperature=0.2,\n",
    "    max_output_tokens=4096\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c979e9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is a framework designed to simplify the development of applications powered by large language models (LLMs). It provides a standardized way to build applications that:\n",
      "\n",
      "*   **Connect to LLMs:** It offers integrations with various LLMs like OpenAI's GPT models, Cohere, Hugging Face models, and more.\n",
      "*   **Manage Data:** It helps you load, manage, and process data from various sources, including text files, websites, databases, and APIs.\n",
      "*   **Chain LLMs and Components:** It allows you to chain together different LLM calls, data processing steps, and other components to create complex workflows.\n",
      "*   **Build Agents:** It enables the creation of agents that can interact with their environment, make decisions, and take actions based on LLM reasoning.\n",
      "*   **Customize and Extend:** It's designed to be flexible and extensible, allowing you to customize existing components and build your own.\n",
      "\n",
      "In essence, LangChain acts as a toolkit and a framework to streamline the process of building LLM-powered applications, making it easier to integrate LLMs, manage data, and create sophisticated conversational and reasoning systems.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "message = [\n",
    "    (\"system\", \"You are a helpful assistant that can answer questions about LangChain.\"),\n",
    "    (\"user\", \"What is LangChain?\"),\n",
    "]\n",
    "\n",
    "res = chatModel.invoke(message)\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bd866c",
   "metadata": {},
   "source": [
    "## Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdc18761",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"data/langchain.txt\")\n",
    "loaded_data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "706f3cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data/langchain.txt'}, page_content=\"What is LangChain?\\nLangChain is an open source framework for building applications based on large language models (LLMs). LLMs are large deep-learning models pre-trained on large amounts of data that can generate responses to user queriesâ€”for example, answering questions or creating images from text-based prompts. LangChain provides tools and abstractions to improve the customization, accuracy, and relevancy of the information the models generate. For example, developers can use LangChain components to build new prompt chains or customize existing templates. LangChain also includes components that allow LLMs to access new data sets without retraining.\\n\\nRead about Large Language Models (LLMs)\\n\\nWhy is LangChain important?\\nLLMs excel at responding to prompts in a general context, but struggle in a specific domain they were never trained on. Prompts are queries people use to seek responses from an LLM. For example, an LLM can provide an answer to how much a computer costs by providing an estimate. However, it can't list the price of a specific computer model that your company sells. \\n\\nTo do that, machine learning engineers must integrate the LLM with the organizationâ€™s internal data sources and apply prompt engineeringâ€”a practice where a data scientist refines inputs to a generative model with a specific structure and context. \\n\\nLangChain streamlines intermediate steps to develop such data-responsive applications, making prompt engineering more efficient. It is designed to develop diverse applications powered by language models more effortlessly, including chatbots, question-answering, content generation, summarizers, and more.\\n\\nThe following sections describe benefits of LangChain.\\n\\nRepurpose language models\\nWith LangChain, organizations can repurpose LLMs for domain-specific applications without retraining or fine-tuning. Development teams can build complex applications referencing proprietary information to augment model responses. For example, you can use LangChain to build applications that read data from stored internal documents and summarize them into conversational responses. You can create a Retrieval Augmented Generation (RAG) workflow that introduces new information to the language model during prompting. Implementing context-aware workflows like RAG reduces model hallucination and improves response accuracy. \\n\\nSimplify AI development\\nLangChain simplifies artificial intelligence (AI) development by abstracting the complexity of data source integrations and prompt refining. Developers can customize sequences to build complex applications quickly. Instead of programming business logic, software teams can modify templates and libraries that LangChain provides to reduce development time. \\n\\nDeveloper support\\nLangChain provides AI developers with tools to connect language models with external data sources. It is open-source and supported by an active community. Organizations can use LangChain for free and receive support from other developers proficient in the framework.\\n\\nHow does LangChain work?\\nWith LangChain, developers can adapt a language model flexibly to specific business contexts by designating steps required to produce the desired outcome. \\n\\nChains\\nChains are the fundamental principle that holds various AI components in LangChain to provide context-aware responses. A chain is a series of automated actions from the user's query to the model's output. For example, developers can use a chain for:\\n\\nConnecting to different data sources.\\nGenerating unique content.\\nTranslating multiple languages.\\nAnswering user queries. \\nLinks\\nChains are made of links. Each action that developers string together to form a chained sequence is called a link. With links, developers can divide complex tasks into multiple, smaller tasks. Examples of links include:\\n\\nFormatting user input. \\nSending a query to an LLM. \\nRetrieving data from cloud storage.\\nTranslating from one language to another.\\nIn the LangChain framework, a link accepts input from the user and passes it to the LangChain libraries for processing. LangChain also allows link reordering to create different AI workflows. \\n\\nWhat are the core components of LangChain?\\nUsing LangChain, software teams can build context-aware language model systems with the following modules. \\n\\nLLM interface\\nLangChain provides APIs with which developers can connect and query LLMs from their code. Developers can interface with public and proprietary models like GPT, Bard, and PaLM with LangChain by making simple API calls instead of writing complex code.\\n\\nPrompt templates\\nPrompt templates are pre-built structures developers use to consistently and precisely format queries for AI models. Developers can create a prompt template for chatbot applications, few-shot learning, or deliver specific instructions to the language models. Moreover, they can reuse the templates across different applications and language models. \\n\\nAgents\\nDevelopers use tools and libraries that LangChain provides to compose and customize existing chains for complex applications. An agent is a special chain that prompts the language model to decide the best sequence in response to a query. When using an agent, developers provide the user's input, available tools, and possible intermediate steps to achieve the desired results. Then, the language model returns a viable sequence of actions the application can take.  \\n\\nRetrieval modules\\nLangChain enables the architecting of RAG systems with numerous tools to transform, store, search, and retrieve information that refine language model responses. Developers can create semantic representations of information with word embeddings and store them in local or cloud vector databases. \\n\\nMemory\\nSome conversational language model applications refine their responses with information recalled from past interactions. LangChain allows developers to include memory capabilities in their systems. It supports:\\n\\nSimple memory systems that recall the most recent conversations. \\nComplex memory structures that analyze historical messages to return the most relevant results. \\nCallbacks\\nCallbacks are codes that developers place in their applications to log, monitor, and stream specific events in LangChain operations. For example, developers can track when a chain was first called and errors encountered with callbacks. \")]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learnlangchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
