{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4e114fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\LangChain project\\learn-LangChain\\learnlangchain\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "816da9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatModel = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash-lite\",\n",
    "    google_api_key=GEMINI_API_KEY,\n",
    "    temperature=0.2,\n",
    "    max_output_tokens=4096\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c979e9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is a framework designed to simplify the development of applications powered by large language models (LLMs). It provides a standardized way to build applications that:\n",
      "\n",
      "*   **Connect to LLMs:** Interact with various LLMs like OpenAI's GPT models, Google's PaLM, and others.\n",
      "*   **Manage Data:** Load, store, and process data relevant to your application. This includes text documents, websites, databases, and more.\n",
      "*   **Chain Operations:** Chain together different components (LLMs, data retrieval, prompts, etc.) to create complex workflows.\n",
      "*   **Build Agents:** Create autonomous agents that can reason, plan, and take actions based on LLM outputs.\n",
      "\n",
      "In essence, LangChain acts as a toolkit and a structured approach for building LLM-powered applications, making it easier to move from idea to implementation.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "message = [\n",
    "    (\"system\", \"You are a helpful assistant that can answer questions about LangChain.\"),\n",
    "    (\"user\", \"What is LangChain?\"),\n",
    "]\n",
    "\n",
    "res = chatModel.invoke(message)\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bd866c",
   "metadata": {},
   "source": [
    "## Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdc18761",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"data/langchain.txt\")\n",
    "load_data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "706f3cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_data = load_data[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9dc70003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is an open-source framework designed for building applications that utilize large language models (LLMs). It provides tools and abstractions to improve the customization, accuracy, and relevance of the information generated by these models. It allows developers to repurpose LLMs for specific domains, integrate them with internal data sources, and streamline the development of applications like chatbots, question-answering systems, and content generators.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"user\", \"answer this {question} based on the following context: {context} \"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "message = chat_template.format_messages(\n",
    "    question=\"What is LangChain?\",\n",
    "    context=loaded_data\n",
    ")\n",
    "\n",
    "res = chatModel.invoke(message)\n",
    "print(res.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learnlangchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
